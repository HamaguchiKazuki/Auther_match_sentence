{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find word --> 福沢,諭吉\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43064_ruby_24472.zip is download\n",
      "./data_files/45257_ruby_18658.zip is download\n",
      "./data_files/45664_ruby_24519.zip is download\n",
      "./data_files/46684_ruby_26314.zip is download\n",
      "./data_files/46685_ruby_24921.zip is download\n",
      "./data_files/46686_ruby_24922.zip is download\n",
      "./data_files/46734_ruby_25781.zip is download\n",
      "./data_files/46826_ruby_24770.zip is download\n",
      "./data_files/46827_ruby_24772.zip is download\n",
      "./data_files/46848_ruby_42407.zip is download\n",
      "./data_files/46890_ruby_25782.zip is download\n",
      "./data_files/47030_ruby_26828.zip is download\n",
      "./data_files/47054_ruby_29646.zip is download\n",
      "./data_files/47061_ruby_28378.zip is download\n",
      "./data_files/47063_ruby_32086.zip is download\n",
      "./data_files/47149_ruby_27921.zip is download\n",
      "./data_files/47150_ruby_27922.zip is download\n",
      "./data_files/47151_ruby_27923.zip is download\n",
      "./data_files/47152_ruby_27924.zip is download\n",
      "./data_files/47219_ruby_33285.zip is download\n",
      "./data_files/47293_ruby_33286.zip is download\n",
      "./data_files/47295_ruby_28353.zip is download\n",
      "./data_files/47343_ruby_42674.zip is download\n",
      "./data_files/47353_ruby_42675.zip is download\n",
      "./data_files/49756_ruby_33301.zip is download\n",
      "./data_files/49757_ruby_33300.zip is download\n",
      "./data_files/49778_ruby_42045.zip is download\n",
      "./data_files/50273_ruby_35109.zip is download\n",
      "./data_files/50298_ruby_42406.zip is download\n",
      "./data_files/50307_ruby_35111.zip is download\n",
      "./data_files/50545_ruby_36803.zip is download\n",
      "./data_files/50553_ruby_36804.zip is download\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def grep(target_file, input_word):\n",
    "    grep_list = [line[:-1] for line in [line for line in open(target_file) if line.find(input_word)>=0]]\n",
    "    return grep_list\n",
    "\n",
    "def download_file(url):\n",
    "    dirpath = './data_files/'\n",
    "    fname =  dirpath + url.split('/')[-1]\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open (fname, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "        return fname\n",
    "    return False\n",
    "\n",
    "def zip_extract(fname):\n",
    "    dirpath = './data_files/'\n",
    "    zfile = zipfile.ZipFile(fname)\n",
    "    zfile.extractall(dirpath)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #　保存ファイルの場所\n",
    "    dirpath = './data_files/'\n",
    "    \n",
    "    # 福沢諭吉テキストurlのリストを作る！\n",
    "    target_file = 'aozora_word_list_utf8.csv'\n",
    "    input_word = input('find word --> ')\n",
    "    text_url_list = [line.split(',')[45] for line in grep(target_file, input_word)]\n",
    "    \n",
    "    #サーバーからデータをダウンロード && ファイルの展開\n",
    "    for url in text_url_list:\n",
    "        fname = download_file(url)\n",
    "        # fname = './data_files/43029_ruby_23223.zip' #deback\n",
    "        if fname:\n",
    "            print('{} is download'.format(fname))\n",
    "            zip_extract(fname)\n",
    "        !sleep 1.0\n",
    "\n",
    "    #すべて展開する\n",
    "    # txt_list =[./data_files/kyoto_gakkono_ki.txt]\n",
    "    txt_list = fnmatch.filter(os.listdir(dirpath), '*.txt')\n",
    "    print(len(fname) == len(txt_list))\n",
    "    \n",
    "    #txt_list全体にdirpathを加える\n",
    "    mapped_txt_list = map(lambda txt_path:dirpath+txt_path, txt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明治五年申五月朔日、社友早矢仕氏とともに京都にいたり、名所旧跡はもとよりこれを訪うに暇あらず、博覧会の見物ももと余輩上京の趣意にあらず、まず府下の学校を一覧せんとて、知る人に案内を乞い、諸処の学校に行\n",
      "\n",
      "\n",
      "\n",
      "難きほどのものなれば、貧富ともに勉むべきは学問にして、ただその教場をして仙境ならしめざること、吾々のつねに注意して怠らざるところなれば、学生諸氏もおのおの自から心してこの注意を空しゅうせしむるなかれ。\n"
     ]
    }
   ],
   "source": [
    "# 正規表現処理を関数化\n",
    "# mapped_txt_listはgenerateで構成されているため一度使うと消える\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    # ヘッダ部分の除去\n",
    "    text = re.split('-{5,}', text)[2]\n",
    "    # フッタ部分の除去\n",
    "    text = re.split('底本：', text)[0]\n",
    "    # |の除去\n",
    "    text = text.replace('｜', '')\n",
    "    text = text.replace('|', '')\n",
    "    # ルビの除去\n",
    "    text = re.sub('《.+?》', '', text)\n",
    "    # 入力注の除去\n",
    "    text = re.sub('［＃.+?］', '', text)\n",
    "    # 空行の除去\n",
    "    text = re.sub('\\n\\n', '\\n', text)\n",
    "    text = re.sub('\\u3000', '', text)\n",
    "    # CR,LFの除去\n",
    "    text = re.sub('\\r', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_sjis_text = \"\" # 処理済みテキストの格納\n",
    "\n",
    "    # ファイル読込み、内部表現化\n",
    "    for text in mapped_txt_list:\n",
    "        f = codecs.open(text, \"r\", \"sjis\")\n",
    "        sjis_text = f.read()\n",
    "        f.close()    \n",
    "        sjis_text = normalize_text(sjis_text)\n",
    "        all_sjis_text += sjis_text #テキストに保存\n",
    "        \n",
    "    # 整形結果確認   \n",
    "    print(all_sjis_text[:100])\n",
    "    print('\\n\\n')\n",
    "    print(all_sjis_text[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.308985615542687\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenneizerインスタンスの生成 \n",
    "t = Tokenizer()\n",
    "\n",
    "# テキストを引数として、形態素解析の結果、名詞のみの配列で抽出する関数を定義 \n",
    "def extract_words(text):\n",
    "    tokens = t.tokenize(text)\n",
    "    return [token.base_form for token in tokens if  token.part_of_speech.split(',')[0] in ['名詞','動詞','形容詞'] if token.part_of_speech.split(',')[1] in ['一般', 'サ変接続', '固有名詞', '形容動詞語幹', '副詞可能', '自立']]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 全体のテキストを句点で区切った配列にする。\n",
    "    sentence_list = all_sjis_text.split('。')\n",
    "\n",
    "    # それぞれの文章を単語リストに変換\n",
    "    word_list = [extract_words(sentence)for sentence in sentence_list]\n",
    "    \n",
    "    # 単語リストの結果を一部表示\n",
    "    for word in word_list:\n",
    "        print(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=2897, size=100, alpha=0.025)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(291211, 409745)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vecの使い方を調べる\n",
    "#適切なハイパーパラメータを決める\n",
    "\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    word_list, \n",
    "    sg = 1, #skip-gram :on\n",
    "    size = 100, # 次元\n",
    "    window = 15, #similar_words \n",
    "    hs = 0,\n",
    ")\n",
    "print(model)\n",
    "\n",
    "model.train(word_list, total_examples=len(word_list), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free word -->a\n",
      "aは類似性がありません\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamaguchikazuki/.pyenv/versions/3.6.5/envs/ppgVC/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "#福沢諭吉に関連するワードを任意で入力して見つけよう！\n",
    "\n",
    "# 結果の確認\n",
    "w1='諭吉'\n",
    "w2= input('free word -->')\n",
    "try:\n",
    "    #２つの単語の類似性を数値で出す。\n",
    "    print(model.wv.similarity(w1, w2))\n",
    "    \n",
    "    print('\\n') # 改行\n",
    "    \n",
    "    #他の類似性の高い単語の表示\n",
    "    print('類似性が高いワード')\n",
    "    pos_w = model.wv.most_similar(positive=w2, topn=5)\n",
    "    for item in pos_w:\n",
    "        print(item[0], item[1])\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print('類似性が低いワード')\n",
    "    neg_w = model.wv.most_similar(negative=w2, topn=5)\n",
    "    for item in neg_w:\n",
    "        print(item[0], item[1])\n",
    "        \n",
    "except:\n",
    "    print('{}は類似性がありません'.format(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
