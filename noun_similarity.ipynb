{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "./data_files/43029_ruby_23223.zip is download\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def download_file(url):\n",
    "    dirpath = './data_files/'\n",
    "    fname =  dirpath + url.split('/')[-1]\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open (fname, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "        return fname\n",
    "    return False\n",
    "\n",
    "def zip_extract(fname):\n",
    "    dirpath = './data_files/'\n",
    "    zfile = zipfile.ZipFile(fname)\n",
    "    zfile.extractall(dirpath)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #　保存ファイルの場所\n",
    "    dirpath = './data_files/'\n",
    "    \n",
    "    # 福沢諭吉テキストurlのリストを作る！\n",
    "    !grep 福沢,諭吉 aozora_word_list_utf8.csv > yukichi.csv\n",
    "    text_url_list = [line.split(',')[45] for line in open('yukichi.csv')]\n",
    "    \n",
    "    #サーバーからデータをダウンロード && ファイルの展開\n",
    "    for url in text_url_list:\n",
    "        #fname = download_file(url)\n",
    "        fname = './data_files/43029_ruby_23223.zip' #deback\n",
    "        if fname:\n",
    "            print('{} is download'.format(fname))\n",
    "            zip_extract(fname)\n",
    "        !sleep 1.0\n",
    "\n",
    "    #すべて展開する\n",
    "    # txt_list =[./data_files/kyoto_gakkono_ki.txt]\n",
    "    txt_list = fnmatch.filter(os.listdir(dirpath), '*.txt')\n",
    "    print(len(fname) == len(txt_list))\n",
    "    \n",
    "    #txt_list全体にdirpathを加える\n",
    "    mapped_txt_list = map(lambda txt_path:dirpath+txt_path, txt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明治五年申五月朔日、社友早矢仕氏とともに京都にいたり、名所旧跡はもとよりこれを訪うに暇あらず、博覧会の見物ももと余輩上京の趣意にあらず、まず府下の学校を一覧せんとて、知る人に案内を乞い、諸処の学校に行\n",
      "\n",
      "\n",
      "\n",
      "難きほどのものなれば、貧富ともに勉むべきは学問にして、ただその教場をして仙境ならしめざること、吾々のつねに注意して怠らざるところなれば、学生諸氏もおのおの自から心してこの注意を空しゅうせしむるなかれ。\n"
     ]
    }
   ],
   "source": [
    "# 正規表現処理を関数化\n",
    "# mapped_txt_listはgenerateで構成されているため一度使うと消える\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "def processing_regular_expression(text):\n",
    "    # ヘッダ部分の除去\n",
    "    text = re.split('-{5,}', text)[2]\n",
    "    # フッタ部分の除去\n",
    "    text = re.split('底本：', text)[0]\n",
    "    # |の除去\n",
    "    text = text.replace('｜', '')\n",
    "    text = text.replace('|', '')\n",
    "    # ルビの除去\n",
    "    text = re.sub('《.+?》', '', text)\n",
    "    # 入力注の除去\n",
    "    text = re.sub('［＃.+?］', '', text)\n",
    "    # 空行の除去\n",
    "    text = re.sub('\\n\\n', '\\n', text)\n",
    "    text = re.sub('\\u3000', '', text)\n",
    "    # CR,LFの除去\n",
    "    text = re.sub('\\r', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_sjis_text = \"\" # 処理済みテキストの格納\n",
    "\n",
    "    # ファイル読込み、内部表現化\n",
    "    for text in mapped_txt_list:\n",
    "        f = codecs.open(text, \"r\", \"sjis\")\n",
    "        sjis_text = f.read()\n",
    "        f.close()    \n",
    "        sjis_text = processing_regular_expression(sjis_text)\n",
    "        all_sjis_text += sjis_text #テキストに保存\n",
    "        \n",
    "    # 整形結果確認   \n",
    "    print(all_sjis_text[:100])\n",
    "    print('\\n\\n')\n",
    "    print(all_sjis_text[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明治\n",
      "五\n",
      "年\n",
      "申\n",
      "五月\n",
      "朔日\n",
      "社友\n",
      "早\n",
      "矢\n",
      "氏\n",
      "京都\n",
      "名所旧跡\n",
      "これ\n",
      "暇\n",
      "博覧\n",
      "会\n",
      "見物\n",
      "もと\n",
      "余\n",
      "輩\n",
      "上京\n",
      "趣意\n",
      "府下\n",
      "学校\n",
      "一覧\n",
      "人\n",
      "案内\n",
      "乞い\n",
      "諸処\n",
      "学校\n",
      "待遇\n",
      "塾舎\n",
      "講堂\n",
      "ところ\n"
     ]
    }
   ],
   "source": [
    "# mainは少なくする\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenneizerインスタンスの生成 \n",
    "t = Tokenizer()\n",
    "\n",
    "# テキストを引数として、形態素解析の結果、名詞のみの配列で抽出する関数を定義 \n",
    "def extract_words(text):\n",
    "    tokens = t.tokenize(text)\n",
    "    return [token.surface for token in tokens if  token.part_of_speech.split(',')[0] in ['名詞']]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 全体のテキストを句点で区切った配列にする。\n",
    "    sentence_list = all_sjis_text.split('。')\n",
    "\n",
    "    # それぞれの文章を単語リストに変換\n",
    "    word_list = [extract_words(sentence)for sentence in sentence_list]\n",
    "\n",
    "    # 単語リストの結果を一部表示\n",
    "    for word in word_list[0]:\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vecの使い方を調べる\n",
    "#適切なハイパーパラメータを決める\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# size: 圧縮次元数\n",
    "# min_count: 出現頻度の低いものをカットする\n",
    "# window: 前後の単語を拾う際の窓の広さを決める\n",
    "# iter: 機械学習の繰り返し回数(デフォルト:5)十分学習できていないときにこの値を調整する\n",
    "# model.wv.most_similarの結果が1に近いものばかりで、model.dict['wv']のベクトル値が小さい値ばかりの \n",
    "# ときは、学習回数が少ないと考えられます。\n",
    "# その場合、iterの値を大きくして、再度学習を行います。\n",
    "\n",
    "# 事前準備したword_listを使ってWord2Vecの学習実施\n",
    "model = word2vec.Word2Vec(word_list, size=100, alpha=0.01, window=5, min_count=3, iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.97601598e-02  3.63006443e-03 -7.41567016e-02 -5.55482768e-02\n",
      "  5.32528246e-03 -4.51689325e-02  4.87040030e-03 -1.04562258e-02\n",
      "  8.87917057e-02  6.83920234e-02  1.50601760e-01  9.03183408e-03\n",
      "  1.40525103e-01 -3.51149999e-02  7.06507340e-02  7.66725242e-02\n",
      " -6.78969920e-02 -8.79880339e-02  1.98746398e-02 -5.22150695e-02\n",
      "  5.70226088e-02  1.20128412e-02  3.49547938e-02  4.12294157e-02\n",
      " -1.40134394e-02 -7.62532428e-02 -1.19028147e-02  8.68743435e-02\n",
      " -9.69357640e-02  1.36763668e-02 -4.21256162e-02 -3.80258225e-02\n",
      "  6.91056103e-02  7.86385462e-02 -6.39136285e-02 -5.63166961e-02\n",
      "  1.50873914e-01 -1.45532086e-01 -2.03896984e-02  1.37454227e-01\n",
      "  1.63418353e-01  8.59540701e-02  2.25330871e-02 -3.82669299e-04\n",
      "  3.29813361e-02 -8.64155591e-02  4.30007419e-03 -3.43955569e-02\n",
      "  2.91459430e-02 -4.46299836e-02  3.20232734e-02  1.03695415e-01\n",
      "  5.77519939e-04 -3.41199711e-02  1.38481655e-05 -2.09218338e-02\n",
      "  9.49757099e-02 -5.86823747e-02 -6.14457158e-03  4.02374007e-02\n",
      " -1.64970122e-02  4.68434095e-02  4.25373465e-02  7.76763260e-02\n",
      "  9.24499147e-03 -6.33860230e-02  1.90545265e-02 -7.16215791e-03\n",
      "  6.36342391e-02 -8.82785302e-03  5.99658815e-04 -1.78095493e-02\n",
      " -4.38056840e-03  7.92853013e-02  4.80236486e-02 -8.56995210e-02\n",
      " -6.20109364e-02  1.08906046e-01 -5.24763856e-03  5.77786006e-02\n",
      " -2.64405040e-03 -5.11050373e-02  2.03844961e-02 -6.11797795e-02\n",
      " -8.07085484e-02  1.07581973e-01 -1.91608742e-02 -7.53367543e-02\n",
      " -1.07878435e-03 -5.90029918e-02 -1.38627866e-03  4.29110974e-02\n",
      "  8.40430111e-02 -4.77543883e-02  6.00388795e-02 -4.31590490e-02\n",
      "  1.41054969e-02  7.02049658e-02 -1.96175650e-03 -1.01143848e-02]\n"
     ]
    }
   ],
   "source": [
    "#他にも適切な確認方法がないか調べる\n",
    "\n",
    "# 結果の確認1\n",
    "# 一つ一つの単語は100次元のベクトルになっています。 \n",
    "# 「世間」のベクトル値を確認します。\n",
    "print(model.__dict__['wv']['金'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "どころ 0.4725894629955292\n",
      "府 0.4475650489330292\n",
      "上野 0.4118836522102356\n",
      "強盗 0.41098856925964355\n",
      "介 0.40858179330825806\n",
      "受 0.4079661965370178\n",
      "つもり 0.3988129496574402\n",
      "役目 0.39686426520347595\n",
      "暴政 0.3637733459472656\n",
      "名目 0.3621255159378052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamaguchikazuki/.pyenv/versions/3.6.5/envs/ppgVC/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "#下に出てくる警告を調べできれば表示させないようにする\n",
    "\n",
    "# 結果の確認2\n",
    "# 関数most_similarを使って「世間」の類似単語を調べます \n",
    "ret = model.wv.most_similar(positive=['命']) \n",
    "for item in ret:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
